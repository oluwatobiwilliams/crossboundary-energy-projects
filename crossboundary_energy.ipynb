{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n",
      "HTML page parsed successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This project will retrieve data on Crossboundary Energy\n",
    "# Specifically data on projects completed with across different clients in various countries\n",
    "\n",
    "# Author: Tobi Williams Babatunde\n",
    "\n",
    "# Import libraries\n",
    "import requests \n",
    "import lxml\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "base_url = \"https://crossboundaryenergy.com/projects\"\n",
    "\n",
    "# Setup crawling parameters\n",
    "headers = {\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Cache-Control\": \"max-age=0\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\"\n",
    "}\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "\n",
    "# Load the webpage\n",
    "driver.get(base_url)\n",
    "\n",
    "# Define the amount of scrolling (in pixels) and the delay between scrolls\n",
    "scroll_increment = 500  # Scroll down by 500 pixels each time\n",
    "scroll_delay = 1  # Delay in seconds between each scroll\n",
    "\n",
    "# Scroll down gradually until the bottom of the page is reached\n",
    "page_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "scroll_position = 0\n",
    "while scroll_position < page_height:\n",
    "    driver.execute_script(f\"window.scrollTo(0, {scroll_position});\")\n",
    "    time.sleep(scroll_delay)\n",
    "    scroll_position += scroll_increment\n",
    "    page_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "# Once at the bottom of the page, retrieve the page source\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Close the WebDriver session\n",
    "driver.quit()\n",
    "\n",
    "# Now you can parse the HTML content using BeautifulSoup or any other method\n",
    "\n",
    "try:\n",
    "    # Parse the HTML content\n",
    "    soup_1 = BeautifulSoup(page_source, 'lxml')\n",
    "    print('HTML page parsed successfully\\n')\n",
    "except Exception as e:\n",
    "    print('Failed to retrieve the HTML content. Exception:{}'.format(e))\n",
    "\n",
    "project_name = soup_1.find_all(\"h2\",\"subtitle mb-sm w-full grow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 23/23"
     ]
    }
   ],
   "source": [
    "# Retrieve data for each project\n",
    "project_list = []\n",
    "project_data = {}\n",
    "\n",
    "base_project_url = \"https://crossboundaryenergy.com/project/\"\n",
    "\n",
    "# Iterate through each project page\n",
    "counter = 0\n",
    "for item in project_name:\n",
    "    \n",
    "    # Format each project name for use in url request\n",
    "    project = item.get_text().lower().replace(\" â€“ \",\" \").replace(\" \",\"-\")\n",
    "\n",
    "    # Handle some project names that don't follow the general rule\n",
    "    if project == 'national-cement-nakuru':\n",
    "        project = 'nc-nakuru'\n",
    "    elif project == 'brush-manufacturers':\n",
    "        project = 'teepee-brush-manufacturers'\n",
    "    else:\n",
    "        project = project\n",
    "\n",
    "    try:\n",
    "        # Request for project url\n",
    "        response = requests.get(base_project_url+project, headers=headers)\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        # print('HTML page parsed successfully\\n')\n",
    "\n",
    "        country = soup.find(\"div\",\"font-subtitle\").get_text()\n",
    "        project_title = item.get_text()\n",
    "\n",
    "        # Generation Size, Customer Segment, Mounting Type\n",
    "        generation_customer_mounting = soup.find_all(\"div\",\"py-sm first:pt-0 flex flex-row gap-lg justify-between items-center border-b border-textColor\")\n",
    "        try:\n",
    "            generation_size = generation_customer_mounting[0].findChild(\"span\",\"body text-right\").get_text()\n",
    "            customer_segment = generation_customer_mounting[1].find(\"span\", \"body scale-100\").get_text()\n",
    "            mounting_type = generation_customer_mounting[2].find(\"span\", \"body scale-100\").get_text()\n",
    "        except Exception as retryGeneration:\n",
    "            generation_size = generation_customer_mounting[1].findChild(\"span\",\"body text-right\").get_text()\n",
    "            customer_segment = generation_customer_mounting[2].find(\"span\", \"body scale-100\").get_text()\n",
    "            mounting_type = generation_customer_mounting[3].find(\"span\", \"body scale-100\").get_text()\n",
    "\n",
    "        # Commission date, Estimated overall renewable energy contribution\n",
    "        commission_date_re_contribution = soup.find_all(\"div\",\"py-sm last:pb-0 flex flex-row gap-lg justify-between items-center border-b border-textColor last:border-b-0\")\n",
    "        commission_date = commission_date_re_contribution[0].find(\"span\", \"body text-right\").get_text()\n",
    "        re_contribution = commission_date_re_contribution[1].find(\"span\", \"body text-right\").get_text()\n",
    "\n",
    "        # Partners\n",
    "        partner_list = soup.find_all(\"div\",\"py-sm first:pt-0 last:pb-0 flex flex-row gap-lg justify-between items-center border-b border-textColor last:border-b-0\")\n",
    "        try:\n",
    "            panel_count = partner_list[0].find(\"span\", \"body text-right\").get_text()\n",
    "            partners = partner_list[1].find(\"span\", \"body text-right\").get_text()\n",
    "        except Exception as retryPartners:\n",
    "            panel_count = None\n",
    "            partners = partner_list[0].find(\"span\", \"body text-right\").get_text()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "        # Store data in dictionary\n",
    "        project_data['project_name'] = project_title\n",
    "        project_data['country'] = country\n",
    "        project_data['generation_size'] = generation_size\n",
    "        project_data['customer_segment'] = customer_segment\n",
    "        project_data['mounting_type'] = mounting_type\n",
    "        project_data['panel_count'] = panel_count\n",
    "        project_data['commission_date'] = commission_date\n",
    "        project_data['re_contribution'] = re_contribution\n",
    "        project_data['partners'] = partners\n",
    "\n",
    "        # Compile project data\n",
    "        project_list.append(project_data)\n",
    "        project_data = {} \n",
    "\n",
    "        counter+=1\n",
    "\n",
    "        # progress bar\n",
    "        print(f\"\\rProgress: {counter}/{len(project_name)}\", end='', flush=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Failed to retrieve the HTML content. Exception:{}'.format(e))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project_name': 'Balama',\n",
       " 'country': 'Mozambique',\n",
       " 'generation_size': '11.2 MWp',\n",
       " 'customer_segment': 'Mining',\n",
       " 'mounting_type': 'Ground',\n",
       " 'panel_count': None,\n",
       " 'commission_date': 'Q2 2023',\n",
       " 're_contribution': '35%',\n",
       " 'partners': 'Solarcentury Africa'}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check output\n",
    "project_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved data to file\n"
     ]
    }
   ],
   "source": [
    "# Save project data list to file withPython native capability\n",
    "# Define fieldnames\n",
    "fieldnames = project_list[0].keys()\n",
    "\n",
    "# Write the data to a csv file\n",
    "with open('crossboundary_energy_projects.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Write header and rows\n",
    "    writer.writeheader()\n",
    "    writer.writerows(project_list)\n",
    "\n",
    "print(\"Successfully saved data to file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
